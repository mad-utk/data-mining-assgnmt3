# -*- coding: utf-8 -*-
"""KDD.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/10qkG7o3U-y4o9BVL1HK_R_SO9MCh2hVI

# The KDD process :

1. Selection: Identifying the target dataset.
2. Preprocessing: Cleaning, transforming, and enriching the data.
3. Transformation: Getting the data into the right form or structure.
4. Data Mining: Applying algorithms to extract patterns.
5. Interpretation/Evaluation: Analyzing the patterns and turning them into knowledge.
6. Deployment: Implementing the results into the organization's operations.
"""

# mount google drive
from google.colab import drive
drive.mount("/content/gdrive")
file_path = '/content/gdrive/MyDrive/Sem-I/CMPE-255 Data Mining/Assignments3/KDD/Amazon_popular_books_dataset.csv'

"""# Phase 1: Selection"""

import pandas as pd

# Load the dataset
amazon_books_df = pd.read_csv(file_path)

# Display the first few rows
amazon_books_df.head()

"""# Phase 2: Preprocessing"""

# Check for missing values in each column
missing_values = amazon_books_df.isnull().sum()

# Percentage of missing values
missing_percentage = (missing_values / len(amazon_books_df)) * 100

# Combine the data into a dataframe for a better view
missing_df = pd.DataFrame({'Missing Values': missing_values, 'Percentage (%)': missing_percentage})

# Display columns with missing values
missing_df[missing_df['Missing Values'] > 0].sort_values(by='Percentage (%)', ascending=False)

"""- Drop columns with more than 90% missing values as they are unlikely to provide significant insights.
- For categorical columns with missing values, we can replace the missing values with a placeholder like "Unknown" or use the mode (most frequent value) of that column.
- For numerical columns with missing values, we can replace the missing values with the median or mean of that column.
"""

# Drop columns with more than 90% missing values
columns_to_drop = missing_df[missing_df['Percentage (%)'] > 90].index
amazon_books_df = amazon_books_df.drop(columns=columns_to_drop)

# Display the shape of the dataframe after dropping columns
amazon_books_df.shape

"""- For categorical columns, we'll replace missing values with the placeholder "Unknown".
- For numerical columns, we'll replace missing values with the median of that column (since the median is less sensitive to outliers).
"""

# Identify categorical and numerical columns
categorical_columns = amazon_books_df.select_dtypes(include=['object']).columns
numerical_columns = amazon_books_df.select_dtypes(exclude=['object']).columns

# Replace missing values
for column in categorical_columns:
    amazon_books_df[column].fillna('Unknown', inplace=True)

for column in numerical_columns:
    median_value = amazon_books_df[column].median()
    amazon_books_df[column].fillna(median_value, inplace=True)

# Check if there are any missing values left
remaining_missing = amazon_books_df.isnull().sum().sum()
remaining_missing

""" Identifying and Handling Outliers"""

# Function to detect outliers using IQR
def detect_outliers(dataframe, column):
    Q1 = dataframe[column].quantile(0.25)
    Q3 = dataframe[column].quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR

    return dataframe[(dataframe[column] < lower_bound) | (dataframe[column] > upper_bound)]

# Detect outliers for numerical columns
outliers_data = {}
for column in numerical_columns:
    outliers = detect_outliers(amazon_books_df, column)
    outliers_data[column] = len(outliers)

# Display the count of outliers for each numerical column
outliers_data

"""Convert Data Types (if necessary)"""

# Check data types of the columns
data_types = amazon_books_df.dtypes
data_types

# Convert the 'rating' column to numerical format by extracting the numeric value
amazon_books_df['rating'] = amazon_books_df['rating'].str.extract('(\d+\.\d+)').astype(float)

# Convert the 'timestamp' column to datetime format
amazon_books_df['timestamp'] = pd.to_datetime(amazon_books_df['timestamp'])

# Check the data types again to confirm the changes
updated_data_types = amazon_books_df[['rating', 'timestamp']].dtypes
updated_data_types

"""# Phase 3: Transformation
3.1 Feature Engineering
**bold text**
A couple of potential features to derive:
- From the categories column, we can extract the primary category for each book.
- From the delivery column, we can extract whether free delivery is available.
"""

# Extract primary category from the 'categories' column
amazon_books_df['primary_category'] = amazon_books_df['categories'].str.extract(r'\"(.*?)\"')

# Extract information about free delivery from the 'delivery' column
amazon_books_df['free_delivery'] = amazon_books_df['delivery'].str.contains('FREE delivery', case=False).astype(int)

# Display the first few rows to check the new features
amazon_books_df[['primary_category', 'free_delivery']].head()

"""# Phase 4: Data Mining

Let's start with some descriptive statistics for our numerical columns.


"""

# Descriptive statistics for numerical columns
descriptive_stats = amazon_books_df.describe(include=[float, int])
descriptive_stats

"""Let's start with the distribution of book ratings."""

import matplotlib.pyplot as plt
import seaborn as sns

# Set the style for seaborn
sns.set_style("whitegrid")

# Plot the distribution of book ratings
plt.figure(figsize=(10, 6))
sns.histplot(amazon_books_df['rating'], bins=30, kde=True, color='skyblue')
plt.title('Distribution of Book Ratings')
plt.xlabel('Rating')
plt.ylabel('Number of Books')
plt.show()

"""let's visualize the distribution of final book prices."""

# Plot the distribution of final book prices
plt.figure(figsize=(10, 6))
sns.histplot(amazon_books_df['final_price'], bins=50, kde=True, color='coral')
plt.title('Distribution of Final Book Prices')
plt.xlabel('Final Price ($)')
plt.ylabel('Number of Books')
plt.show()

""" let's explore the relationship between book ratings and the number of reviews to see if more highly-rated books tend to get more reviews. We'll use a scatter plot for this visualization."""

# Scatter plot to show the relationship between ratings and review counts
plt.figure(figsize=(12, 7))
sns.scatterplot(data=amazon_books_df, x='rating', y='reviews_count', alpha=0.6, color='mediumseagreen')
plt.title('Relationship between Ratings and Review Counts')
plt.xlabel('Rating')
plt.ylabel('Review Count')
plt.show()

"""# Phase 5: Interpretation/Evaluation

In this phase, we'll evaluate the insights obtained during the data mining phase and interpret their significance. We'll also attempt to answer any business or research questions and provide actionable insights.

From our analysis so far:

    Highly Rated Books: The majority of the books in this dataset are highly rated, with ratings between 4.5 and 5. This suggests that the dataset comprises popular books that are well-received by readers.

    Book Prices: Most books are priced between $10 and $20, with a few outliers priced significantly higher. This provides a general price range for popular books on Amazon.

    Relationship Between Ratings and Reviews: While there isn't a clear linear relationship between ratings and the number of reviews, books with higher ratings (between 4.5 and 5) tend to have a wider range of review counts. This suggests that a high rating doesn't necessarily guarantee a high number of reviews, but highly-rated books have the potential to attract a significant number of reviews.

    Delivery Options: Approximately 62% of the books offer free delivery, which might be a factor influencing their popularity.

Given these insights:

    For Authors/Publishers: Ensuring high-quality content can lead to better ratings, potentially attracting more reviews and increasing the book's visibility. Offering competitive prices (in the $10-$20 range) and free delivery can also make a book more appealing to potential readers.

    For Amazon: Since the majority of popular books offer free delivery, this feature can be highlighted in promotions to attract more buyers. Additionally, Amazon could consider promoting books with high ratings but fewer reviews to increase their visibility.

# Phase 6: Deployment

In a real-world scenario, this phase involves implementing the discovered knowledge into the organization's operations. The insights obtained can be used to drive business strategies, improve operations, or develop new products/services.

For our EDA:

    A detailed report summarizing the findings can be shared with stakeholders.
    If this analysis was part of a larger project (e.g., building a recommendation system), the insights could guide feature engineering and model selection.

Lastly, to facilitate easy deployment and sharing, we can encapsulate our analysis in a Jupyter notebook (as we've done here) or use tools like PyCaret to deploy models.
"""